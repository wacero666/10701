{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "# import Levenshtein as L\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchnlp.nn import WeightDropLSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "dataset = np.load('./greenday/midis_array_drum_greenday.npy')\n",
    "\n",
    "split_ratio = 0.9\n",
    "train_dataset = []\n",
    "val_dataset = []\n",
    "for song in dataset:\n",
    "    train_split = int(split_ratio * len(song))\n",
    "    train_dataset.append(song[:train_split])\n",
    "    val_dataset.append(song[train_split:])\n",
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.p = 0.95\n",
    "        self.seq_len = 70\n",
    "        self.std = 5\n",
    "        \n",
    "    def sample_seq_len_(self):\n",
    "        rand_p = np.random.random_sample()\n",
    "        if rand_p < self.p:\n",
    "            seq_mean = self.seq_len\n",
    "        else:\n",
    "            seq_mean = self.seq_len // 2\n",
    "        return int(np.random.normal(seq_mean, self.std))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            rand_idx = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            rand_idx = np.arange(len(self.dataset))\n",
    "        concate_dataset = torch.from_numpy(np.hstack(self.dataset[rand_idx]))\n",
    "        num_iter = len(concate_dataset) // self.batch_size\n",
    "        concate_dataset = concate_dataset[:num_iter*self.batch_size].view(self.batch_size, -1)\n",
    "        concate_dataset.transpose_(0,1)\n",
    "        index = 0\n",
    "        while index < len(concate_dataset):\n",
    "            seq_len = self.sample_seq_len_();\n",
    "            if index + seq_len > len(concate_dataset):\n",
    "                break\n",
    "            yield concate_dataset[index:index+seq_len-1], concate_dataset[index+1:index+seq_len]\n",
    "            index += seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MusicModel(nn.Module):\n",
    "\n",
    "    def __init__(self, note_size, embed_size, nlayers):\n",
    "        super(MusicModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(note_size, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size, hidden_size=embed_size, num_layers=nlayers, dropout=0.65)\n",
    "        self.linear = nn.Linear(embed_size, note_size)\n",
    "        self.linear.weight = self.embedding.weight\n",
    "        \n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, seq_batch): # L x B\n",
    "        seq_batch = self.embedding(seq_batch) # L x B x E\n",
    "        seq_batch, hidden = self.rnn(seq_batch) # L x B x H\n",
    "        seq_batch = self.linear(seq_batch)\n",
    "        return seq_batch, hidden\n",
    "    \n",
    "    def generate(self, seq, n_notes):\n",
    "        generated_notes = []\n",
    "        embed = self.embedding(seq).unsqueeze(1) # L x 1 x E\n",
    "        output_lstm, hidden = self.rnn(embed) # L x 1 x H\n",
    "        output = output_lstm[-1] # 1 x H\n",
    "        logits = self.linear(output) # 1 x V\n",
    "        scores = F.gumbel_softmax(logits)\n",
    "        _,current_note = torch.max(scores,dim=1) # 1 x 1\n",
    "        generated_notes.append(current_note)\n",
    "        if n_notes > 1:\n",
    "            for i in range(n_notes-1):\n",
    "                embed = self.embedding(current_note).unsqueeze(0) # 1 x 1 x E\n",
    "                output_lstm, hidden = self.rnn(embed, hidden) # 1 x 1 x H\n",
    "                output = output_lstm[0] # 1 x H\n",
    "                logits = self.linear(output) # V\n",
    "                scores = F.gumbel_softmax(logits)\n",
    "                _,current_note = torch.max(scores,dim=1) # 1\n",
    "                generated_notes.append(current_note)\n",
    "        return torch.cat(generated_notes,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trainer\n",
    "class MusicModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1.2e-6)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        n_notes = 0\n",
    "        for inputs, targets in self.train_loader:\n",
    "            num_batches += 1\n",
    "            batch_loss, n_note = self.train_batch(inputs, targets)\n",
    "            epoch_loss += batch_loss\n",
    "            n_notes += n_note\n",
    "            if (num_batches % 100 == 0):\n",
    "                print ('[TRAIN]  Iter [%d]   Loss: %.4f'\n",
    "                          % (num_batches, batch_loss / n_note))\n",
    "        epoch_loss = epoch_loss / n_notes\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        output, hidden = self.model(inputs)\n",
    "        loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item(), output.size(0) * output.size(1)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        n_notes = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in self.val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "                output, hidden = self.model(inputs)\n",
    "                loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "                epoch_loss += loss.item()\n",
    "                n_notes += output.size(0) * output.size(1)\n",
    "            epoch_loss = epoch_loss / n_notes\n",
    "            print('[VAL] Val Loss: %.4f' % epoch_loss)\n",
    "            self.val_losses.append(epoch_loss)\n",
    "    \n",
    "    def save(self):\n",
    "        model_path = os.path.join('./greenday_experiments', self.run_id, 'model-{}.pt'.format(self.epochs))\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        print (\"loaded model\")\n",
    "    \n",
    "    def generate(self, seed, n_notes):\n",
    "        self.model.eval()\n",
    "        seq = np.array(seed.split(), dtype=int)\n",
    "        seq = torch.from_numpy(seq).to(DEVICE)\n",
    "        output = model.generate(seq, n_notes)\n",
    "        return output.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./greenday_experiments/drum\n"
     ]
    }
   ],
   "source": [
    "run_id = \"drum\"\n",
    "if not os.path.exists('./greenday_experiments'):\n",
    "    os.mkdir('./greenday_experiments')\n",
    "if not os.path.exists('./greenday_experiments/%s' % run_id):\n",
    "    os.mkdir('./greenday_experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./greenday_experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicModel(\n",
      "  (embedding): Embedding(129, 256)\n",
      "  (rnn): LSTM(256, 256, num_layers=2, dropout=0.65)\n",
      "  (linear): Linear(in_features=256, out_features=129, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MusicModel(129, 256, 2)\n",
    "train_loader = MusicDataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = MusicDataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "trainer = MusicModelTrainer(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "                            max_epochs=NUM_EPOCHS, run_id=run_id)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [1/15]   Loss: 2.5953\n",
      "[VAL] Val Loss: 2.2583\n",
      "[TRAIN]  Epoch [2/15]   Loss: 2.0475\n",
      "[VAL] Val Loss: 2.0468\n",
      "[TRAIN]  Epoch [3/15]   Loss: 1.8675\n",
      "[VAL] Val Loss: 1.9286\n",
      "[TRAIN]  Epoch [4/15]   Loss: 1.7401\n",
      "[VAL] Val Loss: 1.7624\n",
      "[TRAIN]  Epoch [5/15]   Loss: 1.6423\n",
      "[VAL] Val Loss: 1.6883\n",
      "[TRAIN]  Epoch [6/15]   Loss: 1.5728\n",
      "[VAL] Val Loss: 1.6077\n",
      "[TRAIN]  Epoch [7/15]   Loss: 1.4745\n",
      "[VAL] Val Loss: 1.4908\n",
      "[TRAIN]  Epoch [8/15]   Loss: 1.3610\n",
      "[VAL] Val Loss: 1.3617\n",
      "[TRAIN]  Epoch [9/15]   Loss: 1.2293\n",
      "[VAL] Val Loss: 1.2520\n",
      "[TRAIN]  Epoch [10/15]   Loss: 1.1073\n",
      "[VAL] Val Loss: 1.1498\n",
      "[TRAIN]  Epoch [11/15]   Loss: 1.0031\n",
      "[VAL] Val Loss: 1.0830\n",
      "[TRAIN]  Epoch [12/15]   Loss: 0.9271\n",
      "[VAL] Val Loss: 0.9864\n",
      "[TRAIN]  Epoch [13/15]   Loss: 0.8509\n",
      "[VAL] Val Loss: 0.9333\n",
      "[TRAIN]  Epoch [14/15]   Loss: 0.7925\n",
      "[VAL] Val Loss: 0.8968\n",
      "[TRAIN]  Epoch [15/15]   Loss: 0.7397\n",
      "[VAL] Val Loss: 0.8312\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30  # set to super large value at first\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.evaluate()\n",
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36,  40,  40,  36,  36,  41,  36,  36,  40,  40,  36,  36,  36,\n",
       "        36, 128,  36,  36,  40,  40,  36, 128,  36,  36, 128,  36,  40,\n",
       "        40,  36,  36, 128,  36,  36,  40,  40,  36, 128,  36,  40,  40,\n",
       "        36, 128,  36,  40,  40,  53,  36,  40,  40,  36, 128,  36,  40,\n",
       "        40,  36,  36,  40,  40,  36, 128,  36,  40,  40,  36, 128,  36,\n",
       "        40,  40,  36, 128,  40,  40,  36, 128,  36,  36,  40,  40,  36,\n",
       "        36, 128,  36,  40,  40,  36, 128,  36,  40,  36, 128,  36,  40,\n",
       "        40,  36, 128,  36,  40,  40,  36,  40,  40, 128,  40,  40,  36,\n",
       "        36,  36, 128,  36,  36, 128,  36,  36,  36,  36, 128,  36,  36,\n",
       "        40,  40,  36,  36, 128,  36,  36, 128,  36,  36, 128,  36,  36,\n",
       "       128,  36,  36,  40,  40,  36,  36, 128,  36,  36, 128,  36,  36,\n",
       "       128,  36,  36,  57,  57,   0,   0,   0,  40,  40,  43,  36,  36,\n",
       "        53,  36,  36,  40,  40,  40,  43,  36,  40,  36,  36,  36, 128,\n",
       "        36,  36,  40,  40,  36, 128,  36,  36, 128,  36,  40,  40,  36,\n",
       "       128,  36,  40,  40,  36, 128,  36,  40,  40,  36,  57,  69, 128,\n",
       "        36,  36, 128,  36,  40,  40, 128,  40, 128,  40,  43,  36, 128,\n",
       "        36,  36, 128,  36, 128,  36, 128,  36,  40,  40,  36, 128,  36,\n",
       "        40,   0,  36,  40,  40,  40,  40,  36, 128,  36,  40,  40,  36,\n",
       "       128,  40,  40,  36, 128,  36,  36,  40,  40,  69,  36,  36, 128,\n",
       "        36,  36,  40,  40,  36, 128,  36,  36,  57,  36,  36,  40,  40,\n",
       "        36, 128,  36,  36, 128,  36,  40,  40,  36, 128,  36,  40,  40,\n",
       "        36,  40,  40,  36,  41,  40,  40,  40, 128,  40,  40, 128,  40,\n",
       "       128,  36,  36, 128,  36,  40,  40,  36, 128,  36, 128,  36,  40,\n",
       "        40,  36, 128,  36,  40,  40,  36,  36, 128,  36,  40,  40,  36,\n",
       "       128,  36, 128,  36, 128,  36,  36, 128,  36,  40,  40,  36, 128,\n",
       "        36,  40,  40,  36, 128,  36,  40,  40,  36, 128,  36,  40,  40,\n",
       "        36,  36, 128,  36,  40, 128,  40,  36,  36, 128,  36,  40,  40,\n",
       "        36,  36, 128,  36,  36,  40,   0,  36,  40,  40,  36,  36, 128,\n",
       "        36, 128,  36,  40,  40, 128,  40,  40,  36, 128,  36, 128,  36,\n",
       "        40,  40,  36,  40,  40,  36, 128,  36,  40, 128,  40,  40,  36,\n",
       "        36, 128,  36,  40,  40,  36, 128,  36,  36, 128,  40,  40,  36,\n",
       "       128,  36,  36, 128,  36,  36,  40,  40,  40, 128,  40,  40,  36,\n",
       "       128,  36,  40,  40,  36,  36, 128,  36,  36,  40,  40,  36,  36,\n",
       "       128,  36,  36,  40,  40,  36, 128,  36,  40,  43,  36,  36,  40,\n",
       "        40,  36,  36,  40, 128,  36, 128,  36,  40,  40,  36, 128,  36,\n",
       "        36,  40,  40,  36, 128,  36, 128,  36, 128,  36,  40, 128,  40,\n",
       "       128,  36,  40,  40,  36, 128,  40,  40,  36,  36,  53, 128,  36,\n",
       "        40,  40,  36,  36, 128,  36,  36,  40,  40,  36, 128,  36, 128,\n",
       "        36,  36, 128,  36,  36,  40,  40,  36,  36, 128,  36,  36,  40,\n",
       "        40,  36,  36,   0,  36,  36,  40,  40,  36,  36,  40,  36, 128,\n",
       "        36,  36,  40,  40,  36, 128,  36,  40,  40,  36, 128,  36,  40,\n",
       "        40,  36,  36,  40,  40,  36,  36,  36, 128,  36,  40,  40,  36,\n",
       "       128,  36,  36,  40,  40,  36,   0,  36,  57,  40,  40,  36, 128,\n",
       "        36,  36, 128,  36,  40, 128,  36,  36,  40,  40, 128,  36, 128,\n",
       "        36,  40, 128,  36,  36,  36,  36,  36,   0,  47,  40,   0,   0,\n",
       "        40,   0,  36, 128,  36,  40,   0,  36,  36,   0,   0,  40,  40,\n",
       "         0,   0,  36,  36, 128,  36,  36,  40,  40,  36,  36,   0,  36,\n",
       "        36, 128,  36,  36,  40,  40,  36,  36,  36,   0,   0,  36,  36,\n",
       "         0,   0,   0,  36,  36, 128,  36, 128,  36,  36, 128,  36,  36,\n",
       "        36,   0,  40,  40,  36,   0,  36,   0,  36,   0,  36,  40,  40,\n",
       "         0,  36,  36, 128,  36,  36,  40,   0,  40,   0,  36,  36,  36,\n",
       "        36, 128,  36,  36,  40,  40,  36,   0,  36,  36, 128,  36,  36,\n",
       "        40,  40,  36,  36,   0,   0,  36,  36,  40,  40,  40,   0,  40,\n",
       "       128,  40, 128,  40, 128,  40, 128,  40, 128,  40, 128,  40, 128,\n",
       "        40,  40,  36,  36, 128,  36,  36,  40,   0,  36, 128,  36,  40,\n",
       "        40, 128,  40,  40,  36,  36,   0,   0,  40,  40,   0,   0,  36,\n",
       "        36,   0,   0,  40,  40, 128,  40, 128,  40,  36,   0,  36,   0,\n",
       "        40,  40,  36,   0,  36,  36,   0,   0,  40,   0,   0,   0,  36,\n",
       "        36, 128,  36,  36,  40,   0,  40,   0,  36,  36, 128,  36,  36,\n",
       "        40,  40,  40,  40,  36,  36, 128,  36,  36,  40,  40,  36,  36,\n",
       "         0,   0,  36,  36, 128,  36,  36,  36,   0,  36,  36,  36,   0,\n",
       "        36,  36, 128,  36,  36,  36,  36,  40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.load('./greenday_experiments/bass/model-10.pt')\n",
    "# from collections import Counter\n",
    "# first_note = []\n",
    "# for song in dataset:\n",
    "#      first_note.append(song[0])\n",
    "# Counter(first_note)\n",
    "gen = np.array([36] + list(trainer.generate(\"36\", 800)))\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_hot_bass(gen):\n",
    "    gen_one_hot = []\n",
    "\n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == 128:\n",
    "            continue\n",
    "        one_hot = np.zeros((128,1))\n",
    "        if gen[i] != 0:\n",
    "            if i == 0 or gen[i] != gen[i-1]:\n",
    "                one_hot[gen[i]] = 1\n",
    "            else:\n",
    "                one_hot[gen[i]] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./try_bass.npy', gen_one_hot)\n",
    "    \n",
    "def gen_one_hot_drum(gen):\n",
    "    gen_one_hot = []\n",
    "\n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == 128:\n",
    "            continue\n",
    "        one_hot = np.zeros((128,1))\n",
    "        if gen[i] != 0:\n",
    "            if i == 0 or gen[i] != gen[i-1]:\n",
    "                one_hot[gen[i]] = 1\n",
    "            else:\n",
    "                one_hot[gen[i]] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./try_drum.npy', gen_one_hot)\n",
    "\n",
    "def gen_one_hot_guitar(gen):\n",
    "    gen_one_hot = []\n",
    "    \n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == len(chord_vocab):\n",
    "            continue\n",
    "        one_hot = np.zeros((128, 1))\n",
    "        chord = chord_vocab[gen[i]]\n",
    "        if i == 0 or gen[i] != gen[i-1]:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 1\n",
    "        else:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./try_guitar.npy', gen_one_hot)\n",
    "\n",
    "gen_one_hot_drum(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
