{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "# import Levenshtein as L\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchnlp.nn import WeightDropLSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EXPERIMENT_PATH = '../greenday_experiments'\n",
    "GENERATION_PATH = '../greenday_generation'\n",
    "DATA_PATH = '../greenday_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "dataset = np.load(os.path.join(DATA_PATH, 'midis_array_guitar_greenday.npy'))\n",
    "chord_vocab = np.load(os.path.join(DATA_PATH, 'chord_vocab_greenday.npy'))\n",
    "\n",
    "split_ratio = 0.9\n",
    "split = int(split_ratio * len(dataset))\n",
    "train_dataset = []\n",
    "val_dataset = []\n",
    "for song in dataset:\n",
    "    train_split = int(split_ratio * len(song))\n",
    "    train_dataset.append(song[:train_split])\n",
    "    val_dataset.append(song[train_split:])\n",
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)\n",
    "# train_dataset = dataset[:split]\n",
    "# val_dataset = dataset[split:]\n",
    "\n",
    "print (train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.p = 0.95\n",
    "        self.seq_len = 70\n",
    "        self.std = 5\n",
    "        \n",
    "    def sample_seq_len_(self):\n",
    "        rand_p = np.random.random_sample()\n",
    "        if rand_p < self.p:\n",
    "            seq_mean = self.seq_len\n",
    "        else:\n",
    "            seq_mean = self.seq_len // 2\n",
    "        return int(np.random.normal(seq_mean, self.std))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            rand_idx = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            rand_idx = np.arange(len(self.dataset))\n",
    "        concate_dataset = torch.from_numpy(np.hstack(self.dataset[rand_idx]))\n",
    "        num_iter = len(concate_dataset) // self.batch_size\n",
    "        concate_dataset = concate_dataset[:num_iter*self.batch_size].view(self.batch_size, -1)\n",
    "        concate_dataset.transpose_(0,1)\n",
    "        index = 0\n",
    "        while index < len(concate_dataset):\n",
    "            seq_len = self.sample_seq_len_();\n",
    "            if index + seq_len > len(concate_dataset):\n",
    "                break\n",
    "            yield concate_dataset[index:index+seq_len-1], concate_dataset[index+1:index+seq_len]\n",
    "            index += seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MusicModel(nn.Module):\n",
    "\n",
    "    def __init__(self, note_size, embed_size, nlayers):\n",
    "        super(MusicModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(note_size, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size, hidden_size=embed_size, num_layers=nlayers, dropout=0.5)\n",
    "        self.linear = nn.Linear(embed_size, note_size)\n",
    "        self.linear.weight = self.embedding.weight\n",
    "        \n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, seq_batch): # L x B\n",
    "        seq_batch = self.embedding(seq_batch) # L x B x E\n",
    "        seq_batch, hidden = self.rnn(seq_batch) # L x B x H\n",
    "        seq_batch = self.linear(seq_batch)\n",
    "        return seq_batch, hidden\n",
    "    \n",
    "    def generate(self, seq, n_notes):\n",
    "        generated_notes = []\n",
    "        embed = self.embedding(seq).unsqueeze(1) # L x 1 x E\n",
    "        output_lstm, hidden = self.rnn(embed) # L x 1 x H\n",
    "        output = output_lstm[-1] # 1 x H\n",
    "        logits = self.linear(output) # 1 x V\n",
    "        scores = F.gumbel_softmax(logits)\n",
    "        _,current_note = torch.max(scores,dim=1) # 1 x 1\n",
    "        generated_notes.append(current_note)\n",
    "        if n_notes > 1:\n",
    "            for i in range(n_notes-1):\n",
    "                embed = self.embedding(current_note).unsqueeze(0) # 1 x 1 x E\n",
    "                output_lstm, hidden = self.rnn(embed, hidden) # 1 x 1 x H\n",
    "                output = output_lstm[0] # 1 x H\n",
    "                logits = self.linear(output) # V\n",
    "                scores = F.gumbel_softmax(logits)\n",
    "                _,current_note = torch.max(scores,dim=1) # 1\n",
    "                generated_notes.append(current_note)\n",
    "        return torch.cat(generated_notes,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trainer\n",
    "class MusicModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4, weight_decay=1.2e-6)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        n_notes = 0\n",
    "        for inputs, targets in self.train_loader:\n",
    "            num_batches += 1\n",
    "            batch_loss, n_note = self.train_batch(inputs, targets)\n",
    "            epoch_loss += batch_loss\n",
    "            n_notes += n_note\n",
    "            if (num_batches % 100 == 0):\n",
    "                print ('[TRAIN]  Iter [%d]   Loss: %.4f'\n",
    "                          % (num_batches, batch_loss / n_note))\n",
    "        epoch_loss = epoch_loss / n_notes\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        output, hidden = self.model(inputs)\n",
    "        loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item(), output.size(0) * output.size(1)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        n_notes = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in self.val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "                output, hidden = self.model(inputs)\n",
    "                loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "                epoch_loss += loss.item()\n",
    "                n_notes += output.size(0) * output.size(1)\n",
    "            epoch_loss = epoch_loss / n_notes\n",
    "            print('[VAL] Val Loss: %.4f' % epoch_loss)\n",
    "            self.val_losses.append(epoch_loss)\n",
    "    \n",
    "    def save(self):\n",
    "        model_path = os.path.join(EXPERIMENT_PATH, self.run_id, 'model-{}.pt'.format(self.epochs))\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        if DEVICE == 'cpu':\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        print (\"loaded model\")\n",
    "    \n",
    "    def generate(self, seed, n_notes):\n",
    "        self.model.eval()\n",
    "        seq = np.array(seed.split(), dtype=int)\n",
    "        seq = torch.from_numpy(seq).to(DEVICE)\n",
    "        output = model.generate(seq, n_notes)\n",
    "        return output.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"guitar\"\n",
    "if not os.path.exists(EXPERIMENT_PATH):\n",
    "    os.mkdir(EXPERIMENT_PATH)\n",
    "if not os.path.exists(os.path.join(EXPERIMENT_PATH, run_id)):\n",
    "    os.mkdir(os.path.join(EXPERIMENT_PATH, run_id))\n",
    "print(\"Saving models, predictions, and generated words to %s/%s\" % (EXPERIMENT_PATH, run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MusicModel(len(chord_vocab)+1, 512, 3)\n",
    "train_loader = MusicDataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = MusicDataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "trainer = MusicModelTrainer(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "                            max_epochs=NUM_EPOCHS, run_id=run_id)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nll = 1e30  # set to super large value at first\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.evaluate()\n",
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load(os.path.join(EXPERIMENT_PATH, 'guitar/model-15.pt'))\n",
    "# from collections import Counter\n",
    "start = []\n",
    "for song in dataset:\n",
    "    start.append(song[0])\n",
    "# Counter(start).most_common\n",
    "\n",
    "# 186, 122, 182\n",
    "start_note = np.random.choice(start)\n",
    "gen = np.array([start_note] + list(trainer.generate(str(start_note), 800)))\n",
    "print (gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_hot_bass():\n",
    "    gen_one_hot = []\n",
    "\n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == 128:\n",
    "            continue\n",
    "        one_hot = np.zeros((128,1))\n",
    "        if gen[i] != 0:\n",
    "            if i == 0 or gen[i] != gen[i-1]:\n",
    "                one_hot[gen[i]] = 1\n",
    "            else:\n",
    "                one_hot[gen[i]] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save(os.path.join(GENERATION_PATH, 'try_bass.npy'), gen_one_hot)\n",
    "\n",
    "def gen_one_hot_guitar(ind):\n",
    "    gen_one_hot = []\n",
    "    \n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == len(chord_vocab):\n",
    "            continue\n",
    "        one_hot = np.zeros((128, 1))\n",
    "        chord = chord_vocab[gen[i]]\n",
    "        if i == 0 or gen[i] != gen[i-1]:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 1\n",
    "        else:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save(os.path.join(GENERATION_PATH, 'try_guitar_{}.npy'.format(ind)), gen_one_hot)\n",
    "\n",
    "gen_one_hot_guitar(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
