{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "# import Levenshtein as L\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchnlp.nn import WeightDropLSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "# load all that we need\n",
    "dataset = np.load('./greenday/midis_array_guitar_greenday.npy')\n",
    "chord_vocab = np.load('./greenday/chord_vocab_greenday.npy')\n",
    "\n",
    "split_ratio = 0.9\n",
    "split = int(split_ratio * len(dataset))\n",
    "train_dataset = []\n",
    "val_dataset = []\n",
    "for song in dataset:\n",
    "    train_split = int(split_ratio * len(song))\n",
    "    train_dataset.append(song[:train_split])\n",
    "    val_dataset.append(song[train_split:])\n",
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)\n",
    "# train_dataset = dataset[:split]\n",
    "# val_dataset = dataset[split:]\n",
    "\n",
    "print (train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.p = 0.95\n",
    "        self.seq_len = 70\n",
    "        self.std = 5\n",
    "        \n",
    "    def sample_seq_len_(self):\n",
    "        rand_p = np.random.random_sample()\n",
    "        if rand_p < self.p:\n",
    "            seq_mean = self.seq_len\n",
    "        else:\n",
    "            seq_mean = self.seq_len // 2\n",
    "        return int(np.random.normal(seq_mean, self.std))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            rand_idx = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            rand_idx = np.arange(len(self.dataset))\n",
    "        concate_dataset = torch.from_numpy(np.hstack(self.dataset[rand_idx]))\n",
    "        num_iter = len(concate_dataset) // self.batch_size\n",
    "        concate_dataset = concate_dataset[:num_iter*self.batch_size].view(self.batch_size, -1)\n",
    "        concate_dataset.transpose_(0,1)\n",
    "        index = 0\n",
    "        while index < len(concate_dataset):\n",
    "            seq_len = self.sample_seq_len_();\n",
    "            if index + seq_len > len(concate_dataset):\n",
    "                break\n",
    "            yield concate_dataset[index:index+seq_len-1], concate_dataset[index+1:index+seq_len]\n",
    "            index += seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MusicModel(nn.Module):\n",
    "\n",
    "    def __init__(self, note_size, embed_size, nlayers):\n",
    "        super(MusicModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(note_size, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size, hidden_size=embed_size, num_layers=nlayers, dropout=0.5)\n",
    "        self.linear = nn.Linear(embed_size, note_size)\n",
    "        self.linear.weight = self.embedding.weight\n",
    "        \n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, seq_batch): # L x B\n",
    "        seq_batch = self.embedding(seq_batch) # L x B x E\n",
    "        seq_batch, hidden = self.rnn(seq_batch) # L x B x H\n",
    "        seq_batch = self.linear(seq_batch)\n",
    "        return seq_batch, hidden\n",
    "    \n",
    "    def generate(self, seq, n_notes):\n",
    "        generated_notes = []\n",
    "        embed = self.embedding(seq).unsqueeze(1) # L x 1 x E\n",
    "        output_lstm, hidden = self.rnn(embed) # L x 1 x H\n",
    "        output = output_lstm[-1] # 1 x H\n",
    "        logits = self.linear(output) # 1 x V\n",
    "        scores = F.gumbel_softmax(logits)\n",
    "        _,current_note = torch.max(scores,dim=1) # 1 x 1\n",
    "        generated_notes.append(current_note)\n",
    "        if n_notes > 1:\n",
    "            for i in range(n_notes-1):\n",
    "                embed = self.embedding(current_note).unsqueeze(0) # 1 x 1 x E\n",
    "                output_lstm, hidden = self.rnn(embed, hidden) # 1 x 1 x H\n",
    "                output = output_lstm[0] # 1 x H\n",
    "                logits = self.linear(output) # V\n",
    "                scores = F.gumbel_softmax(logits)\n",
    "                _,current_note = torch.max(scores,dim=1) # 1\n",
    "                generated_notes.append(current_note)\n",
    "        return torch.cat(generated_notes,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trainer\n",
    "class MusicModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4, weight_decay=1.2e-6)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        n_notes = 0\n",
    "        for inputs, targets in self.train_loader:\n",
    "            num_batches += 1\n",
    "            batch_loss, n_note = self.train_batch(inputs, targets)\n",
    "            epoch_loss += batch_loss\n",
    "            n_notes += n_note\n",
    "            if (num_batches % 100 == 0):\n",
    "                print ('[TRAIN]  Iter [%d]   Loss: %.4f'\n",
    "                          % (num_batches, batch_loss / n_note))\n",
    "        epoch_loss = epoch_loss / n_notes\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        output, hidden = self.model(inputs)\n",
    "        loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item(), output.size(0) * output.size(1)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        n_notes = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in self.val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "                output, hidden = self.model(inputs)\n",
    "                loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "                epoch_loss += loss.item()\n",
    "                n_notes += output.size(0) * output.size(1)\n",
    "            epoch_loss = epoch_loss / n_notes\n",
    "            print('[VAL] Val Loss: %.4f' % epoch_loss)\n",
    "            self.val_losses.append(epoch_loss)\n",
    "    \n",
    "    def save(self):\n",
    "        model_path = os.path.join('./greenday_experiments', self.run_id, 'model-{}.pt'.format(self.epochs))\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        print (\"loaded model\")\n",
    "    \n",
    "    def generate(self, seed, n_notes):\n",
    "        self.model.eval()\n",
    "        seq = np.array(seed.split(), dtype=int)\n",
    "        seq = torch.from_numpy(seq).to(DEVICE)\n",
    "        output = model.generate(seq, n_notes)\n",
    "        return output.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./greenday_experiments/guitar\n"
     ]
    }
   ],
   "source": [
    "run_id = \"guitar\"\n",
    "if not os.path.exists('./greenday_experiments'):\n",
    "    os.mkdir('./greenday_experiments')\n",
    "if not os.path.exists('./greenday_experiments/%s' % run_id):\n",
    "    os.mkdir('./greenday_experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./greenday_experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicModel(\n",
      "  (embedding): Embedding(285, 512)\n",
      "  (rnn): LSTM(512, 512, num_layers=3, dropout=0.5)\n",
      "  (linear): Linear(in_features=512, out_features=285, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MusicModel(len(chord_vocab)+1, 512, 3)\n",
    "train_loader = MusicDataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = MusicDataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "trainer = MusicModelTrainer(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "                            max_epochs=NUM_EPOCHS, run_id=run_id)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [1/15]   Loss: 3.7648\n",
      "[VAL] Val Loss: 3.3147\n",
      "[TRAIN]  Epoch [2/15]   Loss: 2.6231\n",
      "[VAL] Val Loss: 2.4824\n",
      "[TRAIN]  Epoch [3/15]   Loss: 2.1462\n",
      "[VAL] Val Loss: 2.1781\n",
      "[TRAIN]  Epoch [4/15]   Loss: 1.8281\n",
      "[VAL] Val Loss: 1.8748\n",
      "[TRAIN]  Epoch [5/15]   Loss: 1.5594\n",
      "[VAL] Val Loss: 1.6227\n",
      "[TRAIN]  Epoch [6/15]   Loss: 1.3675\n",
      "[VAL] Val Loss: 1.5021\n",
      "[TRAIN]  Epoch [7/15]   Loss: 1.2289\n",
      "[VAL] Val Loss: 1.4029\n",
      "[TRAIN]  Epoch [8/15]   Loss: 1.1205\n",
      "[VAL] Val Loss: 1.3037\n",
      "[TRAIN]  Epoch [9/15]   Loss: 1.0287\n",
      "[VAL] Val Loss: 1.2307\n",
      "[TRAIN]  Epoch [10/15]   Loss: 0.9504\n",
      "[VAL] Val Loss: 1.1849\n",
      "[TRAIN]  Epoch [11/15]   Loss: 0.8878\n",
      "[VAL] Val Loss: 1.1123\n",
      "[TRAIN]  Epoch [12/15]   Loss: 0.8282\n",
      "[VAL] Val Loss: 1.0782\n",
      "[TRAIN]  Epoch [13/15]   Loss: 0.7783\n",
      "[VAL] Val Loss: 1.0406\n",
      "[TRAIN]  Epoch [14/15]   Loss: 0.7382\n",
      "[VAL] Val Loss: 1.0053\n",
      "[TRAIN]  Epoch [15/15]   Loss: 0.7060\n",
      "[VAL] Val Loss: 0.9870\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30  # set to super large value at first\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.evaluate()\n",
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186   0   9   0 135 135 135   0 135   0 135   0 135   0 135 135   0   0\n",
      " 162   0   0 135 135   0   0 135   0  73   0 191   0 191 191   9   0 162\n",
      "   0 162   0 162   0 162   0 125   0 125   0 125   0   0   0   0   0 125\n",
      " 125 284 125   0   0   0   0   0   0   0 125 125 284 125   0   0   0 122\n",
      " 191 191   0   0   0   0 135 135 135 135   0   0 135 135   0   0 135   0\n",
      " 135 135   0   0 135 135   0   0 135   0   0   0 162 162   0   0 135 218\n",
      " 191   0 191   0 162 162   0   0 191 191   0   0   0   0 191 191 284 191\n",
      " 191   0   0   0   0   0   0   0   0   0   0   0   0   0 162 162 162   0\n",
      " 162 162 284 162 162 162   0 162 162  46   0 225 225 206 169   0 219 234\n",
      " 206 213 206 256  46 183  46   0 206 138 225 225 206 225 243   0 225 225\n",
      " 206  46  46  46 283 206 162   0 219 243 225 225 162   0   0 219 219  46\n",
      "   0 267 267 219 258   0   0 219 267 206   0 243 267 206   0 165 219 206\n",
      "  14 206 206 225 225   0  46 225 243   0 225 219 225   0 225 225 225 219\n",
      " 219  46   0 219 225 219   0 225 225 219  46   0  46   0 206  46 243 219\n",
      " 219  46   0 206 225  46 138 225   0  46 219 138 225 206   0 219 219   0\n",
      " 219 256 267   0 267 160 258 263 206  46 243 225  46 165 225   0 225 219\n",
      "   0   0 225 225 225  46 165 219   0  14 225   0 219 219 219   0 267  46\n",
      " 206 267   0 267  46 243 263   0 277 225 243   0 219 243  46 256   0 263\n",
      " 263 263   0 256 280   0 243 267 268   0   0 243   0   0 206 225 138   0\n",
      " 175 219  46  46  46 225 206 225   0 225 219 225   0 219 219 219  46 219\n",
      " 219 225   0   0   0 225 175 219   0 219   0   0 219 206  14 206   0 267\n",
      " 160 219 267   0 206 263 206   0 225 138   0   0 219 219  46 263   0   0\n",
      " 219 267 210 267   0 263 243   0 225   0 225 225 206   0 219 219  46  46\n",
      " 206   0 206 267  46   0 243 263 206 206   0 225 243 206 219 225   0 219\n",
      " 138   0 225 206 219   0   0 225 219 225   0 219   7 225  26   0   0 219\n",
      "  14 243   0 225 219   0 219 219   0 225   0 225   0 219   0 219 219   0\n",
      " 206 263   0   0 225  92  29   0 206 243 264   0  46  46 267  46 183 225\n",
      "   0 243 243   0 225   0 225   0 219 219 270 225   0 225 225 219 219 219\n",
      "  46   0 268   0 219 206 206 267   0 243  46 267 138   0 225 225 211 190\n",
      "   0 219 219  46   0 219  46 267 267   0   0 225 225   0  46 243 219   0\n",
      " 225 225   0 219 225 211 225 219  46 243  46  46   0 267 206  46 267   0\n",
      " 138 165 243   0 206 138   0 225  46   0 225 225 219   0 225 260 225   0\n",
      " 219  46  46  46  46   0 243   0 267  46 263 225   0 225 225 206 243 267\n",
      " 219   7  46  46 110 267   0 206  46 263 283 284 206 175 284 206 284 243\n",
      " 268 225   0   0 219 138 277   0 263  29 243 206  41   0 267 231 263  46\n",
      "   0 138 267  46 206 206   0 243 138   0 225 243 225   0 225   0 243  46\n",
      "  46   0 206   0 206 138   0 243 138  46 206   0 165 138  46   0   0 225\n",
      "   0 219 219 165 263 138   0  46   0 243 243  64 225 225   0 219 219   0\n",
      " 219 190 263   0   0 225 219   0 219  46   0  46 267 267   0   0 243  14\n",
      " 225   0 219 267 219   0 256 160 206   0 206   0 190  14   0 206 225   0\n",
      " 225 225 219 219   0 219   0   0 225 225 225 219 225   0 219 267   0   0\n",
      " 223 243   0 219 219   0 219 219 225 219   0   0 219  46   0 129 267   0\n",
      " 206   0 206   0 206   0 219 219 225 225   0 225   0 219 219  46   0   0\n",
      " 225  46 225   0   0 219 219 267  46 206   0   0 243 243   0 267  16 263\n",
      " 267   0 267  73   0 225 225 225  46]\n"
     ]
    }
   ],
   "source": [
    "# trainer.load('./experiments/guitar/model-15.pt')\n",
    "# from collections import Counter\n",
    "# start = []\n",
    "# for song in dataset:\n",
    "#     start.append(song[0])\n",
    "# Counter(start).most_common\n",
    "\n",
    "gen = np.array([186] + list(trainer.generate(\"186\", 800)))\n",
    "print (gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_hot_bass():\n",
    "    gen_one_hot = []\n",
    "\n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == 128:\n",
    "            continue\n",
    "        one_hot = np.zeros((128,1))\n",
    "        if gen[i] != 0:\n",
    "            if i == 0 or gen[i] != gen[i-1]:\n",
    "                one_hot[gen[i]] = 1\n",
    "            else:\n",
    "                one_hot[gen[i]] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./try_bass.npy', gen_one_hot)\n",
    "\n",
    "def gen_one_hot_guitar():\n",
    "    gen_one_hot = []\n",
    "    \n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == len(chord_vocab):\n",
    "            continue\n",
    "        one_hot = np.zeros((128, 1))\n",
    "        chord = chord_vocab[gen[i]]\n",
    "        if i == 0 or gen[i] != gen[i-1]:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 1\n",
    "        else:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./try_guitar.npy', gen_one_hot)\n",
    "\n",
    "gen_one_hot_guitar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
