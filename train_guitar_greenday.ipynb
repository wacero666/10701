{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "# import Levenshtein as L\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchnlp.nn import WeightDropLSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "# load all that we need\n",
    "dataset = np.load('./greenday/midis_array_guitar_greenday.npy')\n",
    "chord_vocab = np.load('./greenday/chord_vocab_greenday.npy')\n",
    "\n",
    "split_ratio = 0.9\n",
    "split = int(split_ratio * len(dataset))\n",
    "train_dataset = []\n",
    "val_dataset = []\n",
    "for song in dataset:\n",
    "    train_split = int(split_ratio * len(song))\n",
    "    train_dataset.append(song[:train_split])\n",
    "    val_dataset.append(song[train_split:])\n",
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)\n",
    "# train_dataset = dataset[:split]\n",
    "# val_dataset = dataset[split:]\n",
    "\n",
    "print (train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.p = 0.95\n",
    "        self.seq_len = 70\n",
    "        self.std = 5\n",
    "        \n",
    "    def sample_seq_len_(self):\n",
    "        rand_p = np.random.random_sample()\n",
    "        if rand_p < self.p:\n",
    "            seq_mean = self.seq_len\n",
    "        else:\n",
    "            seq_mean = self.seq_len // 2\n",
    "        return int(np.random.normal(seq_mean, self.std))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            rand_idx = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            rand_idx = np.arange(len(self.dataset))\n",
    "        concate_dataset = torch.from_numpy(np.hstack(self.dataset[rand_idx]))\n",
    "        num_iter = len(concate_dataset) // self.batch_size\n",
    "        concate_dataset = concate_dataset[:num_iter*self.batch_size].view(self.batch_size, -1)\n",
    "        concate_dataset.transpose_(0,1)\n",
    "        index = 0\n",
    "        while index < len(concate_dataset):\n",
    "            seq_len = self.sample_seq_len_();\n",
    "            if index + seq_len > len(concate_dataset):\n",
    "                break\n",
    "            yield concate_dataset[index:index+seq_len-1], concate_dataset[index+1:index+seq_len]\n",
    "            index += seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MusicModel(nn.Module):\n",
    "\n",
    "    def __init__(self, note_size, embed_size, nlayers):\n",
    "        super(MusicModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(note_size, embed_size)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size, hidden_size=embed_size, num_layers=nlayers, dropout=0.5)\n",
    "        self.linear = nn.Linear(embed_size, note_size)\n",
    "        self.linear.weight = self.embedding.weight\n",
    "        \n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, seq_batch): # L x B\n",
    "        seq_batch = self.embedding(seq_batch) # L x B x E\n",
    "        seq_batch, hidden = self.rnn(seq_batch) # L x B x H\n",
    "        seq_batch = self.linear(seq_batch)\n",
    "        return seq_batch, hidden\n",
    "    \n",
    "    def generate(self, seq, n_notes):\n",
    "        generated_notes = []\n",
    "        embed = self.embedding(seq).unsqueeze(1) # L x 1 x E\n",
    "        output_lstm, hidden = self.rnn(embed) # L x 1 x H\n",
    "        output = output_lstm[-1] # 1 x H\n",
    "        logits = self.linear(output) # 1 x V\n",
    "        scores = F.gumbel_softmax(logits)\n",
    "        _,current_note = torch.max(scores,dim=1) # 1 x 1\n",
    "        generated_notes.append(current_note)\n",
    "        if n_notes > 1:\n",
    "            for i in range(n_notes-1):\n",
    "                embed = self.embedding(current_note).unsqueeze(0) # 1 x 1 x E\n",
    "                output_lstm, hidden = self.rnn(embed, hidden) # 1 x 1 x H\n",
    "                output = output_lstm[0] # 1 x H\n",
    "                logits = self.linear(output) # V\n",
    "                scores = F.gumbel_softmax(logits)\n",
    "                _,current_note = torch.max(scores,dim=1) # 1\n",
    "                generated_notes.append(current_note)\n",
    "        return torch.cat(generated_notes,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model trainer\n",
    "class MusicModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, max_epochs=1, run_id='exp'):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4, weight_decay=1.2e-6)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        n_notes = 0\n",
    "        for inputs, targets in self.train_loader:\n",
    "            num_batches += 1\n",
    "            batch_loss, n_note = self.train_batch(inputs, targets)\n",
    "            epoch_loss += batch_loss\n",
    "            n_notes += n_note\n",
    "            if (num_batches % 100 == 0):\n",
    "                print ('[TRAIN]  Iter [%d]   Loss: %.4f'\n",
    "                          % (num_batches, batch_loss / n_note))\n",
    "        epoch_loss = epoch_loss / n_notes\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        output, hidden = self.model(inputs)\n",
    "        loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item(), output.size(0) * output.size(1)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        n_notes = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in self.val_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "                output, hidden = self.model(inputs)\n",
    "                loss = self.criterion(output.view(-1, output.size(2)), targets.contiguous().view(-1))\n",
    "                epoch_loss += loss.item()\n",
    "                n_notes += output.size(0) * output.size(1)\n",
    "            epoch_loss = epoch_loss / n_notes\n",
    "            print('[VAL] Val Loss: %.4f' % epoch_loss)\n",
    "            self.val_losses.append(epoch_loss)\n",
    "    \n",
    "    def save(self):\n",
    "        model_path = os.path.join('./greenday_experiments', self.run_id, 'model-{}.pt'.format(self.epochs))\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        if DEVICE == 'cpu':\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        print (\"loaded model\")\n",
    "    \n",
    "    def generate(self, seed, n_notes):\n",
    "        self.model.eval()\n",
    "        seq = np.array(seed.split(), dtype=int)\n",
    "        seq = torch.from_numpy(seq).to(DEVICE)\n",
    "        output = model.generate(seq, n_notes)\n",
    "        return output.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./greenday_experiments/guitar\n"
     ]
    }
   ],
   "source": [
    "run_id = \"guitar\"\n",
    "if not os.path.exists('./greenday_experiments'):\n",
    "    os.mkdir('./greenday_experiments')\n",
    "if not os.path.exists('./greenday_experiments/%s' % run_id):\n",
    "    os.mkdir('./greenday_experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./greenday_experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicModel(\n",
      "  (embedding): Embedding(285, 512)\n",
      "  (rnn): LSTM(512, 512, num_layers=3, dropout=0.5)\n",
      "  (linear): Linear(in_features=512, out_features=285, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MusicModel(len(chord_vocab)+1, 512, 3)\n",
    "train_loader = MusicDataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = MusicDataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "trainer = MusicModelTrainer(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "                            max_epochs=NUM_EPOCHS, run_id=run_id)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [1/15]   Loss: 3.7648\n",
      "[VAL] Val Loss: 3.3147\n",
      "[TRAIN]  Epoch [2/15]   Loss: 2.6231\n",
      "[VAL] Val Loss: 2.4824\n",
      "[TRAIN]  Epoch [3/15]   Loss: 2.1462\n",
      "[VAL] Val Loss: 2.1781\n",
      "[TRAIN]  Epoch [4/15]   Loss: 1.8281\n",
      "[VAL] Val Loss: 1.8748\n",
      "[TRAIN]  Epoch [5/15]   Loss: 1.5594\n",
      "[VAL] Val Loss: 1.6227\n",
      "[TRAIN]  Epoch [6/15]   Loss: 1.3675\n",
      "[VAL] Val Loss: 1.5021\n",
      "[TRAIN]  Epoch [7/15]   Loss: 1.2289\n",
      "[VAL] Val Loss: 1.4029\n",
      "[TRAIN]  Epoch [8/15]   Loss: 1.1205\n",
      "[VAL] Val Loss: 1.3037\n",
      "[TRAIN]  Epoch [9/15]   Loss: 1.0287\n",
      "[VAL] Val Loss: 1.2307\n",
      "[TRAIN]  Epoch [10/15]   Loss: 0.9504\n",
      "[VAL] Val Loss: 1.1849\n",
      "[TRAIN]  Epoch [11/15]   Loss: 0.8878\n",
      "[VAL] Val Loss: 1.1123\n",
      "[TRAIN]  Epoch [12/15]   Loss: 0.8282\n",
      "[VAL] Val Loss: 1.0782\n",
      "[TRAIN]  Epoch [13/15]   Loss: 0.7783\n",
      "[VAL] Val Loss: 1.0406\n",
      "[TRAIN]  Epoch [14/15]   Loss: 0.7382\n",
      "[VAL] Val Loss: 1.0053\n",
      "[TRAIN]  Epoch [15/15]   Loss: 0.7060\n",
      "[VAL] Val Loss: 0.9870\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30  # set to super large value at first\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.evaluate()\n",
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "[186 284 186 186 186  38 284  38  38 284  38  38  96  96 284  96  96 284\n",
      "  96  96 284  96  96 125 125 125 125 284 125 125 284 125 125 284 125 125\n",
      " 284 125 125 284 125 125 284 125 125 284 125 125 284 125 125 284 125 125\n",
      " 284 125 125 284 125 125 284 125 125 284 125 125 284 125 125 126 126 284\n",
      " 126 126 284 126 126 284 126 126 284 126 126 125 125 125   0 125 125 284\n",
      " 125 125 284 125 125  96  96 194   0 126   0 126 126   0  96  96  96   0\n",
      "  96   0  96  96 284  96  96  24  27 284  27  97  97   0  97   0 125 125\n",
      " 284 125   0   0   0   0   0  24 205  15  15 275  15 284  15  15 182 216\n",
      " 284 284  63 284 198 284 284  97 284  57  97 284 100 284 284 284 137 284\n",
      " 284  15 284  15 284  15 284  15 284  15 284  15 284  15 284  15 284  15\n",
      " 284  15 284  15  15 284  15 284  15 284  15 284  15 284  15 284  15 284\n",
      "  15 284  15 284  15 284  15 284  15 284 281 284 126 126 126  15  15 284\n",
      "  15 284  15 284  15 284  15 284  15 284  15 284  15 284  15  15 126 126\n",
      " 284  15 284  71 284 204 247   9 284 212  42 284 174 284 275 284 275 284\n",
      " 275 284 211  50   9 177 284 275 284 226 284 104  24 284 212 284  24 284\n",
      "  24 284  24 207  38 284  24 284  24 284  15 284  15  15 284  15 284  15\n",
      " 284  15 284  15 284  15 126 284 126 284 126 284 126 125 284 125 284 125\n",
      " 284 125 284 125 284 125 284 125 284 125 182 284 182 168 284 168 284 168\n",
      " 284 168 284 168 284 168 168 284 168 182 284 182 284 182 284 182 182 284\n",
      " 182 284 182 284 182 284 182 182 284 182 284 182 284 182 284 182 284 182\n",
      " 284  97 284 125 284 125 284 125 284 125 284 125 284 125 182 182 182 284\n",
      " 182 284 182 284 182 284 182 284 182 182 284 182 284 182 182 202 284 168\n",
      " 284 168 284 168 168 168 281 284 168 284 168 284 168 284 168 168 168 168\n",
      " 284 168 168 284 168 284 168 168 168 125 125   0   0 178   0  15 182 284\n",
      " 182 284  15 284 182 182 182   0 182 182 284 182 284 182 284 182 284 182\n",
      " 191 284 191 191 284 191 284 191 284 191 284 191 284 191 284 191 191 284\n",
      " 191 284 191 284 191 284 191 182 182 182 284 182 284 182 182 284 182 284\n",
      " 182 284 182 284 182 284 182 284 182 284 182 284 182 284 182 182 125 125\n",
      " 284 125 284 125 284 125 125 125 284 125 284 125 284 125 125 284 125 284\n",
      " 125 284 125 125 284 125 284 125 284 125 284 125 284 125 284 125 284 125\n",
      " 284 125 284 125 284 125 284 125 284 125 125 284 125 125 284 125 125 284\n",
      " 125 125 284 125 284 125 284 125 284 125 284 125 284 125 284 125 284 125\n",
      " 284 125 284 125 182 284 182 284 182 284 182 284 182 182 284 182 284 182\n",
      " 284 182 284 182 284 182 284 182 284 182 182 284 182 182 284 182 186 284\n",
      " 186 186 284 186 284 186 284 186 284 186 284 186 284 186 284 186 284 186\n",
      " 284 186 284 186 284 186 284 186 125 125 284 125 284 125 284 125 284 125\n",
      " 284 125 284 125 125 284 125 284 125 284 125 284 125 125 135 135 135 135\n",
      " 284 135 284 135 284 135 135 122 122 284 122 284 122 122 284 122 284 122\n",
      " 191 191 284 191 284 191 284 191 284 191 284 191 284 191   0 186 186 186\n",
      " 186 284 186   0   0 186 186 186  84  27 284  15 284  93 284  96  96 284\n",
      "  96  96 284  96  96 284  96  96 284  96  96 284  96  96 284  96  96  97\n",
      " 153 284 153 153 153 153 284 153 153 284 153 153 284 153 153 186 186 284\n",
      " 186 186 284 186 186 284 186 186 284 186 186 284 186 186 284 186 186 135\n",
      " 135 135   0 135 135 284 135 135 284 135 135 284 135 135 284 135 135 153\n",
      " 153 153 153 284 153 153 284 153 153]\n"
     ]
    }
   ],
   "source": [
    "trainer.load('greenday_experiments/guitar/model-15.pt')\n",
    "# from collections import Counter\n",
    "start = []\n",
    "for song in dataset:\n",
    "    start.append(song[0])\n",
    "# Counter(start).most_common\n",
    "\n",
    "# 186, 122, 182\n",
    "start_note = np.random.choice(start)\n",
    "gen = np.array([start_note] + list(trainer.generate(str(start_note), 800)))\n",
    "print (gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_hot_bass():\n",
    "    gen_one_hot = []\n",
    "\n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == 128:\n",
    "            continue\n",
    "        one_hot = np.zeros((128,1))\n",
    "        if gen[i] != 0:\n",
    "            if i == 0 or gen[i] != gen[i-1]:\n",
    "                one_hot[gen[i]] = 1\n",
    "            else:\n",
    "                one_hot[gen[i]] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./try_bass.npy', gen_one_hot)\n",
    "\n",
    "def gen_one_hot_guitar(ind):\n",
    "    gen_one_hot = []\n",
    "    \n",
    "    for i in range(len(gen)):\n",
    "        if gen[i] == len(chord_vocab):\n",
    "            continue\n",
    "        one_hot = np.zeros((128, 1))\n",
    "        chord = chord_vocab[gen[i]]\n",
    "        if i == 0 or gen[i] != gen[i-1]:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 1\n",
    "        else:\n",
    "            for c in chord:\n",
    "                one_hot[c] = 0.5\n",
    "        gen_one_hot.append(one_hot)\n",
    "    gen_one_hot = np.hstack(gen_one_hot)\n",
    "    np.save('./greenday_gen/try_guitar_{}.npy'.format(ind), gen_one_hot)\n",
    "\n",
    "gen_one_hot_guitar(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
